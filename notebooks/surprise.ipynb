{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Surprise tester\n",
    "This notebook contains a few tests to see how well Scikit Surprise performs on my data.\n",
    "\n",
    "It uses KNN and SVD as these should be comparable to the KNN and SVC used in my recommender. Surprise doesn't include naive Bayes, decision trees or logistic regression. This is because it focuses on numeric prediction rather than classification.\n",
    "\n",
    "This notebook is configured to be similar to my main config, with the same split of data used in my results. The accuracy here is 55% for SVD and 57% for KNN. This is similar to (though slightly lower than) the collaborative filtering results in my recommender system. This suggests that my collaborative filtering section is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import KNNBasic\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Hacky import for project modules by adding them directly to sys path  \n",
    "modules = str(Path.cwd().parent / \"modules\")\n",
    "\n",
    "if modules not in sys.path:\n",
    "    sys.path.append(modules)\n",
    "    \n",
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config values\n",
    "ratings = load_data.trim_ratings(\n",
    "    load_data.ratings_data(Path.cwd().parent/\"data/book_ratings.db\"), 10, 5\n",
    ")\n",
    "ratings[\"recommend\"] = load_data.set_threshold(ratings, 4)\n",
    "ratings = load_data.set_class_proportions(\n",
    "    ratings, 0.2, 0.8\n",
    ")\n",
    "print(f\"Data ready: {ratings.shape[0]} ratings to use\")\n",
    "\n",
    "# Main train/test split - don't touch test from here onwards\n",
    "train, test = train_test_split(\n",
    "    ratings,\n",
    "    random_state=50,\n",
    "    test_size=0.2,\n",
    "    stratify=ratings[\"recommend\"],\n",
    ")\n",
    "print(f\"Test/train split done: {len(train)} ratings in training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(False, True))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(train[['user_id', 'book_id', 'recommend']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {\n",
    "    \"user_based\": False,\n",
    "}\n",
    "\n",
    "algo = KNNBasic(k=5, sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "# MAE is 1 - accuracy when run on classification data\n",
    "results = cross_validate(algo, data, measures=['MAE'], cv=5, verbose=False)\n",
    "accuracy = 1 - results[\"test_mae\"].mean()\n",
    "print(\"KNN accuracy:\", round(accuracy, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('msc-project': venv)",
   "language": "python",
   "name": "python38564bitmscprojectvenv7ab5a66a7eea4b2bad0897438e4f558f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
