{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Collect ratings from Goodreads\n",
    "This isn't a fully deterministic script. The scraping system is unreliable depending on its connection to Goodreads. It's necessary to collect ratings from clusters of books rather than trying to do everything at once. Add a pause whenever the connection breaks. \n",
    "\n",
    "Once books have more than a few hundred ratings this won't collect all of them - the system for paging through reviews doesn't get along well with automated visits.\n",
    "\n",
    "But the purpose isn't to collect all the data, which would be unfair use of the site anyway. The purpose is just to collect enough ratings to have a useful dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sqlite3\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from selenium import webdriver  \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys  \n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the existing book data and ratings database\n",
    "data_dir = Path.cwd().parent / \"data\"\n",
    "data = pd.read_csv(data_dir / \"book_data_cut.csv\")\n",
    "conn = sqlite3.connect(data_dir / \"book_ratings.db\")\n",
    "\n",
    "# Check how much is currently in the database\n",
    "select_books = conn.execute(\"SELECT COUNT(DISTINCT book_id) FROM book_ratings\")\n",
    "for row in select_books:\n",
    "    print(\"Book count:\", row[0])\n",
    "\n",
    "select_users = conn.execute(\"SELECT COUNT(DISTINCT user_id) FROM book_ratings\")\n",
    "for row in select_users:\n",
    "    print(\"Book count:\", row[0])\n",
    "\n",
    "select_ratings = conn.execute(\"SELECT COUNT(*) FROM book_ratings\")\n",
    "for row in select_ratings:\n",
    "    print(\"Ratings:\", row[0])\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to convert Goodreads descriptive ratings back into 1-5 star ratings\n",
    "ratings = {\n",
    "    \"did not like it\": 1, \n",
    "    \"it was ok\": 2, \n",
    "    \"liked it\": 3, \n",
    "    \"really liked it\": 4, \n",
    "    \"it was amazing\": 5\n",
    "}\n",
    "\n",
    "# FUNCTIONS FOR SCRAPER\n",
    "def initialise(to_do, chrome_options, base, limit):\n",
    "    \"\"\"Creates a connection and begins collecting ratings\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    to_do (list):\n",
    "        List of books in the form of Goodreads IDs\n",
    "        \n",
    "    chrome_options (Options):\n",
    "        Selenium object containing options for the session\n",
    "        \n",
    "    base (str):\n",
    "        The first part of the web address for a Goodreads book page\n",
    "        This will always be https://www.goodreads.com/book/show/\n",
    "        \n",
    "    limit (int):\n",
    "        Max number of ratings to collect per book\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome(\n",
    "        \"chromedriver\", \n",
    "        options=chrome_options\n",
    "    )\n",
    "\n",
    "    # Load the first page and click past any modal that appears\n",
    "    current = to_do.pop()\n",
    "    driver.get(base + str(current))\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'modalOpened'))).click()\n",
    "        driver.refresh()\n",
    "    except TimeoutException:\n",
    "        print(\"Failed on modal check:\", str(current))\n",
    "        failures.append(current)\n",
    "        return 1\n",
    "\n",
    "    # Set up a progress bar\n",
    "    pbar = tqdm(total=len(to_do) + 1, initial=0, leave=True)\n",
    "\n",
    "    # Work through the books, pausing appropriately\n",
    "    # Commit to the database after each books reviews gathered\n",
    "    # Add failures to a global list so I can check them\n",
    "    while to_do:\n",
    "        if get_reviews(current, driver, limit, base):\n",
    "            conn.commit()\n",
    "            pbar.update(1)\n",
    "            time.sleep(5)\n",
    "            current = to_do.pop()\n",
    "            driver.get(base + str(current))\n",
    "        else:\n",
    "            print(\"Failed - pausing\")\n",
    "            failures.append(current)\n",
    "            driver.quit()\n",
    "            pbar.close()\n",
    "            time.sleep(300)\n",
    "            return 1\n",
    "    if get_reviews(current, driver, limit, base):\n",
    "        conn.commit()\n",
    "    else:\n",
    "        print(\"Failed on last one\")\n",
    "        failures.append(current)\n",
    "    driver.quit()\n",
    "    pbar.close()\n",
    "    \n",
    "def get_reviews(book_id, driver, limit, base):\n",
    "    \"\"\"Starting with the webdriver already on a book's page, collect reviews page by page\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    try:\n",
    "        # Look for the reviews section in the html\n",
    "        pause = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"bookReviews\")))\n",
    "    except Exception as e:\n",
    "        failures.append(book_id)\n",
    "        print(\"Failed finding reviews:\", str(book_id), str(type(e)))\n",
    "        return False\n",
    "\n",
    "    while counter < limit: \n",
    "        # Run subfunction to get the reviews\n",
    "        counter += add_reviews_to_database(driver, book_id)\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            # Look for a next page button - this part frequently goes wrong\n",
    "            element = driver.find_element_by_class_name(\"next_page\")\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "        if element.get_attribute(\"class\") == \"next_page disabled\":\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                # Make sure the next page button has loaded before clicking\n",
    "                element = WebDriverWait(driver, 5).until(\n",
    "                    EC.element_to_be_clickable((By.CLASS_NAME, \"next_page\"))).click()\n",
    "            except: \n",
    "                print(\"Failed on click - skipping further pages:\", book_id)\n",
    "                skipped.append(book_id)\n",
    "                return True\n",
    "            try:\n",
    "                # Don't collect next page of reviews until the current one is gone\n",
    "                WebDriverWait(driver, 10).until(EC.staleness_of(element))            \n",
    "            except:\n",
    "                pass\n",
    "    return True\n",
    "\n",
    "def add_reviews_to_database(driver, book_id):\n",
    "    \"\"\"Parse through a page and send ratings and user ids to the database\n",
    "    \"\"\"\n",
    "    page = driver.page_source\n",
    "    doc = BeautifulSoup(page, 'lxml')\n",
    "    reviews = doc.find_all(class_='reviewHeader')\n",
    "    scores = []\n",
    "    for r in reviews:\n",
    "        stars = r.find(class_='staticStars')\n",
    "        if stars:\n",
    "            rating = ratings[stars['title']]\n",
    "            user_id = r.find(class_='user')['href'][11:]\n",
    "            scores.append((book_id, user_id[:user_id.find(\"-\")], rating))\n",
    "    # Send to the database at the end of each page rather than one by one\n",
    "    conn.executemany(\n",
    "        \"REPLACE INTO book_ratings VALUES(?, ?, ?);\",\n",
    "        scores\n",
    "    )\n",
    "    return len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE BOOK LIST \n",
    "# The smaller the review numbers, the more books, so use a small range at first\n",
    "min_reviews = 5\n",
    "max_reviews = 1000\n",
    "to_do = data[\"Goodreads ID\"][data['Review count'].between(min_reviews, max_reviews)].to_list()\n",
    "failures = []\n",
    "print(\"Books to scrape:\", len(to_do))\n",
    "print(\n",
    "    \"Max text reviews:\", \n",
    "    data[\"Text review count\"][data['Review count'] <= max_reviews].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE TO CURRENT DB\n",
    "# Optional cell if I'm going over previously examined books, trying again on failures\n",
    "conn = sqlite3.connect(data_dir / \"book_ratings.db\")\n",
    "\n",
    "select = conn.execute(\"SELECT DISTINCT book_id FROM book_ratings\")\n",
    "done = [book[0] for book in select.fetchall()]\n",
    "\n",
    "to_do = [book for book in to_do if book not in done]\n",
    "print(\"Books not already scraped:\", len(to_do))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE SCRAPER\n",
    "skipped = []\n",
    "chrome_options = Options()  \n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "\n",
    "BASE = 'https://www.goodreads.com/book/show/'\n",
    "LIMIT = 300\n",
    "\n",
    "conn = sqlite3.connect(data_dir / \"book_ratings.db\")\n",
    "\n",
    "# Stop if it fails too much\n",
    "fails = 0\n",
    "while to_do and fails < 6: \n",
    "    initialise(to_do, chrome_options, BASE, LIMIT)\n",
    "    fails += 1\n",
    "\n",
    "# Don't count it as a failure if it only stops because it reaches the end of the list\n",
    "if to_do == 0:\n",
    "    fails -= 1\n",
    "    \n",
    "print(\"Failures:\", len(failures))\n",
    "select = conn.execute(\"SELECT COUNT(DISTINCT book_id) FROM book_ratings\")\n",
    "for row in select:\n",
    "    print(\"In database:\", row[0])\n",
    "        \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('msc-project': venv)",
   "language": "python",
   "name": "python38564bitmscprojectvenv7ab5a66a7eea4b2bad0897438e4f558f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
