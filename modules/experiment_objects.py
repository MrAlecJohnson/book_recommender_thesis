import pickle
import pandas as pd

from modules import hybridise
from modules import vectorise
from modules import load_data
from modules import analyse
from modules import evaluate

from tqdm import tqdm
from pathlib import Path
from sklearn.model_selection import StratifiedKFold
from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression

# Map the names used in settings files to the classes and functions they represent
func_map = {
    "naive_bayes": MultinomialNB,
    "knn": KNeighborsClassifier,
    "decision_tree": DecisionTreeClassifier,
    "svc": SVC,
    "log_regression": LogisticRegression,
    "confidence": hybridise.confidence_hybrid,
    "book_rating": hybridise.book_rating_hybrid,
    "best_of_3": hybridise.best_of_3_hybrid,
    "count": vectorise.vectorise_count,
    "tfidf": vectorise.vectorise_tfidf,
    "lsi": vectorise.vectorise_lsi,
    "nmf": vectorise.vectorise_nmf,
    "style": vectorise.use_styles,
    "random": vectorise.random_vectors,
    "combined": vectorise.style_lsi_combined,
    "separate": vectorise.style_lsi_separate,
}


class ExperimentData:
    """Class to contain all the input data for an experiment,
    including cross-validation folds.
    """

    def __init__(
        self, ratings, train_indexes, test_indexes, training_run, random_state, location
    ):
        """Initialise with:

        ratings (DataFrame):
            The user ratings used in the experiment, with columns book_id,
            user_id, rating and recommend

        train_indexes, test_indexes (array-like):
            Indexes of the training and test sets, generated by something like
            Scikit Learn's StratifiedShuffleSplit

        training_run (bool):
            If True, run in training mode rather than test mode. Training mode
            ignores the test set and just cross-validates on the training set.
            Test mode cross-validates on the training set to train the hybrid,
            then runs all the algorithms on the test set.

        random_state (int):
            To ensure all randomisable function outputs can be replicated

        location (Path):
            Pathlib path specifying the data directory for loading books and ratings
        """
        self.ratings = ratings
        self.training_run = training_run
        self.random_state = random_state
        self.trainset = ratings.iloc[train_indexes]

        gr_to_gutenberg = load_data.map_book_ids("gr_to_gute", location)

        # Load only the relevant book texts
        if self.training_run:
            training_ids_gr = sorted(self.trainset["book_id"].unique().tolist())
            training_ids_gute = [gr_to_gutenberg[i] for i in training_ids_gr]
            self.training_books = load_data.read_books(training_ids_gute, location)
            self.training_vector_index = {
                b: i for i, b in enumerate(self.training_books.keys())
            }

        else:
            self.testset = ratings.iloc[test_indexes]
            ids_gr = sorted(self.ratings["book_id"].unique().tolist())
            ids_gute = [gr_to_gutenberg[i] for i in ids_gr]
            self.books = load_data.read_books(ids_gute, location)
            self.vector_index = {b: i for i, b in enumerate(self.books.keys())}

            training_ids_gr = sorted(self.trainset["book_id"].unique().tolist())
            training_ids_gute = [gr_to_gutenberg[i] for i in training_ids_gr]
            self.training_books = {
                k: v for k, v in self.books.items() if k in training_ids_gr
            }
            self.training_vector_index = {
                b: i for i, b in enumerate(self.training_books.keys())
            }


class Experiment:
    """The main class for running an experiment - initialised from a dataset
    and an experiment json. Can contain ExperimentData and ExperimentFolds
    """

    def __init__(
        self,
        data,
        description,
        vectoriser,
        vectoriser_params,
        cf_algo,
        cf_params,
        content_algo,
        content_params,
        hybrid_algo,
        hybrid_params,
    ):
        """Set up an experiment with:

        data (ExperimentData):
            Specify an ExperimentData object that's already been set up

        description (str):
            Identifier - how the experiment should be described in its results

        vectoriser, cf_algo, content_algo, hybrid_algo (str):
            Short names for the algorithms to use - taken from the func_map dict

        vectoriser_params, cf_params, content_params, hybrid_params (dict):
            Additional parameters for each of the algorithms used
        """
        self.description = description
        self.data = data
        self.vectoriser = vectoriser
        self.vectoriser_params = vectoriser_params
        self.cf_algo = cf_algo
        self.cf_params = cf_params
        self.content_algo = content_algo
        self.content_params = content_params
        self.hybrid_algo = hybrid_algo
        self.hybrid_params = hybrid_params

        # Set up cross-validation folds for the training set
        kf = StratifiedKFold(
            n_splits=5, shuffle=True, random_state=self.data.random_state
        )
        self.folds = [
            ExperimentFold(self, train_fold, val_fold)
            for train_fold, val_fold in kf.split(
                self.data.trainset, self.data.trainset["recommend"]
            )
        ]

    def process_folds(self):
        """Train and predict cf_algo and content_algo on all the training folds
        Used in both training mode and test mode.

        Adds a .results attribute to each of the training folds
        """
        for fold in self.folds:
            fold.process()

    def hybridise_folds(self):
        """Train and predict hybrid_algo on each fold. Adds results to the existing
        .results attribute for each fold. Only used in training mode.

        Must have already run process_folds
        """
        for fold in self.folds:
            fold.hybridise()

    def hybridise_test(self):
        """Train a hybrid classifier on the training folds. Makes no predictions.
        Only used in test mode.

        You can access the newly trained model Experiment.hybrid_model
        """
        # Skip this if using a simple hybrid that doesn't need to train a model
        if self.hybrid_algo in ["confidence", "book_rating", "best_of_3"]:
            return

        combined = pd.concat([fold.results for fold in self.folds])

        # Most hybrid algorithms make use of a mappings dictionary of dataset stats
        self.mappings = {
            "average_ratings": self.data.trainset.groupby("book_id")["rating"]
            .mean()
            .to_dict(),
            "book_review_counts": self.data.trainset["book_id"]
            .value_counts()
            .to_dict(),
            "user_review_counts": self.data.trainset["user_id"]
            .value_counts()
            .to_dict(),
            "random_state": self.data.random_state,
        }

        self.hybrid_model = hybridise.algo_hybrid(
            func_map[self.hybrid_algo],
            combined,
            self.hybrid_params,
            self.mappings,
            False,
        )

    def retrain(self):
        """Retrain cf_algo and content_algo on the full training set. Then use
        these newly trained models and an already trained hybrid model to make
        predictions for the test set. Only used in test mode.

        You can access the final predictions from Experiment.results
        """
        print("Hybrid trained - now retraining cf and content on full training data")
        cf_table = analyse.make_cf_table(self.data.ratings, self.data.trainset)

        print("Creating full book vectors")
        vector_func = func_map[self.vectoriser]
        vectors = vector_func(
            self.data.books, self.data.books.keys(), self.vectoriser_params
        )

        print("Analysing users")
        results = []
        # need to run a different function if using separate vocab and style vectors
        if self.vectoriser == "separate":
            analyser = analyse.analyse_user_plus_style
            cols = [
                "original_index",
                "user_id",
                "book_id",
                "true_class",
                "cf_class",
                "content_class",
                "style_class",
                "cf_probability",
                "content_probability",
                "style_probability",
            ]
        else:
            analyser = analyse.analyse_user
            cols = [
                "original_index",
                "user_id",
                "book_id",
                "true_class",
                "cf_class",
                "content_class",
                "cf_probability",
                "content_probability",
            ]
        # Build a model for each user based on their ratings
        for user in tqdm(self.data.testset["user_id"].unique()):
            results.extend(
                analyser(
                    user,
                    self.data.trainset,
                    self.data.testset,
                    self.data.trainset["recommend"],
                    self.data.testset["recommend"],
                    cf_table,
                    vectors,
                    self.data.vector_index,
                    func_map[self.cf_algo],
                    self.cf_params,
                    func_map[self.content_algo],
                    self.content_params,
                )
            )
        self.results = pd.DataFrame(results, columns=cols)

        # Different ways to hybridise depending on whether rule-based or statistical
        if self.hybrid_algo == "confidence":
            self.results["hybrid_class"] = hybridise.confidence_hybrid(self.results)
        elif self.hybrid_algo == "best_of_3":
            self.results["hybrid_class"] = hybridise.best_of_3_hybrid(self.results)
        elif self.hybrid_algo == "book_rating":
            self.mappings = {
                "average_ratings": self.data.trainset.groupby("book_id")["rating"]
                .mean()
                .to_dict()
            }
            self.results["hybrid_class"] = hybridise.book_rating_hybrid(
                self.results, mappings=self.mappings
            )
        else:
            df, subset = hybridise.prepare_hybrid_df(
                func_map[self.hybrid_algo],
                self.results,
                self.hybrid_params,
                self.mappings,
            )
            self.results["hybrid_class"] = self.hybrid_model.predict(df[subset])

    def evaluate_folds(self):
        """Calculate accuracy metrics for all cross-validation folds. Each fold gets
        a .results attribute. Also produces averages in Experiment.fold_scores

        Used only in training mode.
        """
        self.fold_scores = []
        for fold in self.folds:
            self.fold_scores.append(evaluate.evaluate_results(fold.results))
        self.scores = evaluate.average_folds(self.fold_scores)

    def evaluate_test(self):
        """Calculate accuracy metrics for an experiment's overall results,
        creating a DataFrame in a .results attribute. Used only in training mode.
        """
        self.scores = evaluate.evaluate_results(self.results)

    def pickle_experiment(self, filename):
        """Saves the Experiment to disk for bug-fixing or further analysis.
        """
        pickle.dump(self, open(Path.cwd() / "models" / f"{filename}.pkl", "wb"))
        print(f"Saved {self.description} to the models folder as {filename}.pkl")


class ExperimentFold:
    """A cross-validation fold of an Experiment.
    A list of 5 of these are created when an Experiment is initialised.
    """

    def __init__(self, experiment, train_fold, val_fold):
        """Nearly all of the fold's attributes are inherited from the Experiment

        train_fold and val_fold should be index arrays.
        """
        self.vectoriser = experiment.vectoriser
        self.vectoriser_params = experiment.vectoriser_params
        self.cf_algo = experiment.cf_algo
        self.cf_params = experiment.cf_params
        self.content_algo = experiment.content_algo
        self.content_params = experiment.content_params
        self.hybrid_algo = experiment.hybrid_algo
        self.hybrid_params = experiment.hybrid_params
        self.data = experiment.data.trainset
        self.books = experiment.data.training_books
        self.vector_index = experiment.data.training_vector_index
        self.random_state = experiment.data.random_state

        # Use the index arrays to make dataframes
        # for the fold's training and validation sets
        self.X_train, self.X_val, self.y_train, self.y_val = analyse.splitter(
            self.data, train_fold, val_fold
        )
        # Construct a matrix of users against books for use in collaborative filtering
        self.cf_table = analyse.make_cf_table(self.data, self.data.iloc[train_fold])

    def process(self):
        """Trains and predicts collaborative filtering and content models for the fold

        Stores results in Fold.results

        Could be refactored to avoid repetition of the similar method for Experiments
        """
        # Fit vectoriser to X_train then transform all books in the fold
        # order of vectors will match self.vector_index
        print("Creating book vectors")
        training_ids = self.X_train["book_id"].unique().tolist()
        vector_func = func_map[self.vectoriser]
        vectors = vector_func(self.books, training_ids, self.vectoriser_params)

        print("Analysing users")
        results = []
        # need to run a different function if using separate vocab and style vectors
        if self.vectoriser == "separate":
            analyser = analyse.analyse_user_plus_style
            cols = [
                "original_index",
                "user_id",
                "book_id",
                "true_class",
                "cf_class",
                "content_class",
                "style_class",
                "cf_probability",
                "content_probability",
                "style_probability",
            ]
        else:
            analyser = analyse.analyse_user
            cols = [
                "original_index",
                "user_id",
                "book_id",
                "true_class",
                "cf_class",
                "content_class",
                "cf_probability",
                "content_probability",
            ]
        # Build a model for each user based on their ratings
        for user in tqdm(self.X_val["user_id"].unique()):
            results.extend(
                analyser(
                    user,
                    self.X_train,
                    self.X_val,
                    self.y_train,
                    self.y_val,
                    self.cf_table,
                    vectors,
                    self.vector_index,
                    func_map[self.cf_algo],
                    self.cf_params,
                    func_map[self.content_algo],
                    self.content_params,
                )
            )
        self.results = pd.DataFrame(results, columns=cols)

    def hybridise(self):
        """After running .process() on a Fold, use this to train and
        predict from a hybridiser
        """
        # Create mapping dictionary with basic dataset statistics
        self.mappings = {
            "average_ratings": self.X_train.groupby("book_id")["rating"]
            .mean()
            .to_dict(),
            "book_review_counts": self.X_train["book_id"].value_counts().to_dict(),
            "user_review_counts": self.X_train["user_id"].value_counts().to_dict(),
            "random_state": self.random_state,
        }
        # Run different functions for rule-based and statistical hybrids
        if self.hybrid_algo == "confidence":
            self.results["hybrid_class"] = hybridise.confidence_hybrid(self.results)
        elif self.hybrid_algo == "best_of_3":
            self.results["hybrid_class"] = hybridise.best_of_3_hybrid(self.results)
        elif self.hybrid_algo == "book_rating":
            self.results["hybrid_class"] = hybridise.book_rating_hybrid(
                self.results, mappings=self.mappings
            )
        else:
            self.results["hybrid_class"] = hybridise.algo_hybrid(
                func_map[self.hybrid_algo],
                self.results,
                self.hybrid_params,
                self.mappings,
                True,
            )
